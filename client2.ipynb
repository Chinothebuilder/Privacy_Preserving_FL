{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925ecff1-6fb6-4548-84c5-3c207b89f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tenseal as ts\n",
    "import os\n",
    "import utils\n",
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "from fractions import Fraction\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a8de6b-5843-4afd-9e48-5b801b8934bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and compile Keras model\n",
    "# model = keras.Sequential([\n",
    "    #keras.layers.Flatten(input_shape=(28,28)),\n",
    "    #keras.layers.Dense(128, activation='relu'),\n",
    "    #keras.layers.Dense(256, activation='relu'),\n",
    "    #keras.layers.Dense(10, activation='softmax')])\n",
    "#model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832aa84f-d4c5-430c-a1b5-c991a5862a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "# Define the distribution\n",
    "dist = [0, 10, 10, 10, 4000, 3000, 4000, 5000, 10, 4500]\n",
    "#dist = [4000, 4000, 4000, 3000, 10, 10, 10, 10, 4000, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c53e064-63e9-47d0-99af-2d76e0d7bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the MNIST original dataset to retain only part of the dataset.\n",
    "#x_train = x_train[20000:,:,:]\n",
    "#y_train = y_train[20000:]\n",
    "#x_test = x_test[4000:,:,:]\n",
    "#y_test  = y_test[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a99d1a2-3d7b-4511-be98-8f3463390b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Auxillary methods\n",
    "def getDist(y):\n",
    "    ax = sns.countplot(x = y)\n",
    "    ax.set(title=\"Count of data classes\")\n",
    "    plt.show()\n",
    "\n",
    "def getData(dist, x, y):\n",
    "    dx = []\n",
    "    dy = []\n",
    "    counts = [0 for i in range(10)]\n",
    "    for i in range(len(x)):\n",
    "        if counts[y[i]]<dist[y[i]]:\n",
    "            dx.append(x[i])\n",
    "            dy.append(y[i])\n",
    "            counts[y[i]] += 1\n",
    "        \n",
    "    return np.array(dx), np.array(dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9828264-1b5a-40ae-8b98-f107bcd600c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train = getData(dist, x_train, y_train)\n",
    "getDist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c5c5ddf-ba59-4e9c-afa5-21afb49c95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the MNIST original dataset to retain only part of the dataset.\n",
    "#x_train = x_train[20000:40596,:,:]\n",
    "#y_train = y_train[20000:40596]\n",
    "#x_test = x_test[4000:7139,:,:]\n",
    "#y_test  = y_test[4000:7139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc615c0d-b179-4098-b6c8-36544fceed59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 20540\n",
      "y_train: 20540\n",
      "x_test: 10000\n",
      "y_test: 10000\n"
     ]
    }
   ],
   "source": [
    "# Length of the new dataset\n",
    "print(\"x_train:\", len(x_train))\n",
    "print(\"y_train:\", len(y_train))\n",
    "print(\"x_test:\", len(x_test))\n",
    "print(\"y_test:\", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49c46857-3c3a-4426-9a91-47c385ee8529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                7840      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                100       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,940\n",
      "Trainable params: 7,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the base model\n",
    "new_model = tf.keras.models.load_model('./saved_model/base_model')\n",
    "# Check its architecture.\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3d7bb14-f90f-4b86-8e2c-5e3d040ba36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 950,    0,    3,    2,    2,    6,   11,    1,    5,    0],\n",
       "       [   0, 1110,    6,    4,    1,    1,    3,    0,   10,    0],\n",
       "       [  12,    6,  902,   22,   14,    1,   15,   14,   44,    2],\n",
       "       [   5,    1,   21,  902,    1,   32,    3,   14,   22,    9],\n",
       "       [   1,    4,    5,    0,  918,    0,   12,    0,    7,   35],\n",
       "       [  18,    2,    6,   56,   12,  718,    7,    7,   60,    6],\n",
       "       [  22,    3,   12,    0,   16,   15,  881,    0,    9,    0],\n",
       "       [   3,   23,   24,   10,    7,    0,    0,  924,    3,   34],\n",
       "       [   6,   11,   12,   30,   16,   27,    9,   17,  835,   11],\n",
       "       [  11,    5,    0,   15,   69,    4,    0,   24,   10,  871]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a multiclass confusion matrix before training.\n",
    "predictions = new_model.predict(x_test)\n",
    "confusion = confusion_matrix(y_test, np.argmax(predictions,axis=1))\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634f8bc3-f4f6-420b-8846-f543c6b4ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3539 - sparse_categorical_accuracy: 0.9011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3539418578147888, 0.9010999798774719]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the base_model to see the loss and sparse_categorical_accuracy before training.\n",
    "new_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a894b4b3-e4c7-481a-b1a3-1ea07b9600b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model.\n",
    "new_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2db955-8c6a-4923-a223-56ade49bee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "161/161 [==============================] - 2s 6ms/step - loss: 0.4332 - sparse_categorical_accuracy: 0.8518 - val_loss: 1.1297 - val_sparse_categorical_accuracy: 0.6697\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3536 - sparse_categorical_accuracy: 0.8793 - val_loss: 1.4815 - val_sparse_categorical_accuracy: 0.5940\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.3167 - sparse_categorical_accuracy: 0.8928 - val_loss: 1.8132 - val_sparse_categorical_accuracy: 0.5368\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.2935 - sparse_categorical_accuracy: 0.9011 - val_loss: 1.9683 - val_sparse_categorical_accuracy: 0.5181\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.2776 - sparse_categorical_accuracy: 0.9037 - val_loss: 2.3294 - val_sparse_categorical_accuracy: 0.4988\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.2723 - sparse_categorical_accuracy: 0.9066 - val_loss: 2.2833 - val_sparse_categorical_accuracy: 0.4839\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.2625 - sparse_categorical_accuracy: 0.9103 - val_loss: 2.5190 - val_sparse_categorical_accuracy: 0.4804\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2553 - sparse_categorical_accuracy: 0.9122 - val_loss: 2.5915 - val_sparse_categorical_accuracy: 0.4716\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2515 - sparse_categorical_accuracy: 0.9138 - val_loss: 2.7268 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.2460 - sparse_categorical_accuracy: 0.9144 - val_loss: 2.8402 - val_sparse_categorical_accuracy: 0.4682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e80cb7e50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retraining the base_model to obtain the new weights.\n",
    "new_model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc1a778d-7e66-4dee-8142-456f0470d64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 2.8403 - sparse_categorical_accuracy: 0.4682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8402512073516846, 0.4681999981403351]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the base_model to see the loss and sparse_categorical_accuracy after training.\n",
    "new_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5b7b52-c70e-43a6-bea7-b6411f231d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting weights & bias.\n",
    "# Checking which layers have weights & bias.\n",
    "#for layer in new_model.layers:\n",
    "#    print(layer.name, len(layer.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b134ba67-6dbe-4bf9-b760-869b1199173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_gentry_encrypt (K, r, p, q):\n",
    "    # Extract the weights.\n",
    "    client_weights = new_model.layers[1].get_weights()\n",
    "    # Mask the weights\n",
    "    res_A = [(x + K) for x in client_weights]\n",
    "    \n",
    "    # Splitting the weights array into 2 arrays 'arr0' and 'arr1'\n",
    "    # This is because protobuf has a hardlimit of 2GB, hence, we split the weights into 2 arrays.\n",
    "    arr = np.array(res_A)\n",
    "    arr0, arr1 = np.dsplit(arr, 2)\n",
    "    \n",
    "    #encrypt mask weights A\n",
    "    encrypt_A = [(x + (2*r) + (q*p)) for x in res_A]\n",
    "    # stored the encrpyted weights in dict. \n",
    "    client2_query_gentry = { \"data1\" : encrypt_A,}\n",
    "    \n",
    "    # Store the encrypyted weights \n",
    "    enc_2 = pickle.dumps(client2_query_gentry)\n",
    "    with open(\"client2_enc_gentry\", \"wb\") as file:\n",
    "        file.write(enc_2)\n",
    "    \n",
    "    \n",
    "    return arr0, arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0911460-db23-4000-946d-01e84a463b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c2p gentry time: 19.17099952697754 ms\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "arr0, arr1 = client_gentry_encrypt(-500, 3, 29, 22)\n",
    "t_end = time()\n",
    "print(\"c2p gentry time: {} ms\".format((t_end - t_start) * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a9312-0a01-48e3-836e-63e8ff71a232",
   "metadata": {},
   "source": [
    "### Client Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b93d3b-bc93-4e8b-9506-26d2fa0db465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight encryption time for client: 351942.85440444946 ms\n"
     ]
    }
   ],
   "source": [
    "def encrypt_weights():\n",
    "    #obtain the context from the file \n",
    "    key_query_file = open('key_query', \"rb\")\n",
    "    context_key = pickle.load(key_query_file)\n",
    "    key_query_file.close()\n",
    "\n",
    "    # Recreate the key.\n",
    "    context = ts.context_from(context_key[\"context\"])\n",
    "    \n",
    "    # perform Encryption on the weights for the first group arr0\n",
    "    t_start = time()\n",
    "    enc_v1 = ts.ckks_tensor(context, arr0)\n",
    "    enc_v1_serialised = enc_v1.serialize()\n",
    "    # Perform Encryption on the weights for the second group arr1\n",
    "    enc_v2 = ts.ckks_tensor(context, arr1)\n",
    "    enc_v2_serialised = enc_v2.serialize()\n",
    "    t_end = time()\n",
    "    print(\"weight encryption time for client: {} ms\".format((t_end - t_start) * 1000))\n",
    "    \n",
    "    # Store the encrypted weights in a dict\n",
    "    client2_query = {\"data1\" : enc_v1_serialised, \"data2\" : enc_v2_serialised}\n",
    "    \n",
    "    # Save the encrypted weights in a pickle file\n",
    "    input_dictionary = (client2_query)\n",
    "    file = open('client2_enc', 'wb')\n",
    "    pickle.dump(input_dictionary, file)\n",
    "    file.close()\n",
    "    \n",
    "    return context\n",
    "context = encrypt_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3912f-3b31-4f8d-bce5-e70873e10c09",
   "metadata": {},
   "source": [
    "## Load the updated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60391158-2bd7-4af1-ab59-e7aa327c2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this section, we uload the updated model which have the averaged weights from the server.\n",
    "updated_model = tf.keras.models.load_model('saved_model/updated_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78cc0f1e-412c-4e48-ab95-5453a48bd4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                7840      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                100       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,940\n",
      "Trainable params: 7,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check its architecture\n",
    "updated_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb19b811-8685-4721-9417-1a9336f31114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 951,    0,    3,    2,    3,    7,    9,    1,    4,    0],\n",
       "       [   0, 1109,    5,    3,    1,    1,    4,    0,   12,    0],\n",
       "       [  15,    7,  913,   16,   12,    1,   19,   13,   32,    4],\n",
       "       [   5,    1,   25,  899,    0,   32,    1,   13,   22,   12],\n",
       "       [   2,    4,    6,    0,  900,    0,   14,    0,   11,   45],\n",
       "       [  20,    1,    7,   49,    8,  730,    9,    6,   54,    8],\n",
       "       [  20,    3,    9,    0,    9,   12,  898,    0,    7,    0],\n",
       "       [   4,   21,   23,    8,    9,    0,    0,  920,    0,   43],\n",
       "       [   7,   11,   11,   24,   10,   30,   10,   12,  839,   20],\n",
       "       [   9,    4,    0,   12,   40,    5,    1,   19,   13,  906]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a multiclass confusion matrix before training.\n",
    "predictions = updated_model.predict(x_test)\n",
    "confusion = confusion_matrix(y_test, np.argmax(predictions,axis=1))\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db82e9a-92aa-4df3-a56b-87530642efc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 2.2442 - sparse_categorical_accuracy: 0.4899\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 6s 18ms/step - loss: 0.2513 - sparse_categorical_accuracy: 0.9122 - val_loss: 2.5356 - val_sparse_categorical_accuracy: 0.4868\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 2s 15ms/step - loss: 0.2430 - sparse_categorical_accuracy: 0.9140 - val_loss: 2.7728 - val_sparse_categorical_accuracy: 0.4779\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 2s 13ms/step - loss: 0.2411 - sparse_categorical_accuracy: 0.9141 - val_loss: 2.8963 - val_sparse_categorical_accuracy: 0.4740\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 2s 15ms/step - loss: 0.2340 - sparse_categorical_accuracy: 0.9157 - val_loss: 2.9273 - val_sparse_categorical_accuracy: 0.4718\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 2s 15ms/step - loss: 0.2347 - sparse_categorical_accuracy: 0.9166 - val_loss: 2.9387 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 2s 15ms/step - loss: 0.2315 - sparse_categorical_accuracy: 0.9178 - val_loss: 3.0720 - val_sparse_categorical_accuracy: 0.4689\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 0.2196 - sparse_categorical_accuracy: 0.9217 - val_loss: 3.2256 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 4s 23ms/step - loss: 0.2167 - sparse_categorical_accuracy: 0.9236 - val_loss: 3.2167 - val_sparse_categorical_accuracy: 0.4671\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 2s 13ms/step - loss: 0.2195 - sparse_categorical_accuracy: 0.9221 - val_loss: 3.2043 - val_sparse_categorical_accuracy: 0.4675\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 2s 15ms/step - loss: 0.2141 - sparse_categorical_accuracy: 0.9261 - val_loss: 3.1197 - val_sparse_categorical_accuracy: 0.4668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d3fb637f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the base_model to see the loss and sparse_categorical_accuracy before training.\n",
    "updated_model.evaluate(x_test, y_test)\n",
    "# Compiling the model.\n",
    "updated_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "# Retraining the base_model to obtain the new weights.\n",
    "updated_model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
